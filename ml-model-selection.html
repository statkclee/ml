<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="generator" content="pandoc">
    <title>Software Carpentry: xwMOOC 기계학습</title>
    <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="stylesheet" type="text/css" href="css/bootstrap/bootstrap.css" />
    <link rel="stylesheet" type="text/css" href="css/bootstrap/bootstrap-theme.css" />
    <link rel="stylesheet" type="text/css" href="css/swc.css" />
    <link rel="alternate" type="application/rss+xml" title="Software Carpentry Blog" href="http://software-carpentry.org/feed.xml"/>
    <meta charset="UTF-8" />
    <!-- HTML5 shim, for IE6-8 support of HTML5 elements -->
    <!--[if lt IE 9]>
      <script src="https://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
    
      ga('create', 'UA-59802572-17', 'auto');
      ga('send', 'pageview');
    
    </script>
  </head>
  <body class="lesson">
    <div class="container card">
      <div class="banner">
        <a href="http://software-carpentry.org" title="Software Carpentry">
          <img alt="Software Carpentry banner" src="img/software-carpentry-banner.png" />
        </a>
      </div>
      <article>
      <div class="row">
        <div class="col-md-10 col-md-offset-1">
                    <a href="index.html"><h1 class="title">xwMOOC 기계학습</h1></a>
          <h2 class="subtitle">모형식별 및 선택 (yardstick)</h2>
          <h1 id="predictive-model">1. 기계학습 예측모형 선택 <a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> <a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a></h1>
<p>기계학습 모형을 선정할 때, 인간이 사용하는 경우 <strong>성능 상한(Performance Ceiling)</strong> 을 가장 복잡한 모형으로 잡고, 컴퓨팅 복잡성, 예측 용이성, 해석 편이성을 고려하여 모형을 선정한다. 예를 들어, 비선형 지지도 벡터 머신(Nonlinear SVM) 혹은 확률숲(Random Forest)의 경우 데이터에 대한 접합은 좋지만, 실제 운영환경으로 배포하기가 그다지 좋지는 못하다.</p>
<ol style="list-style-type: decimal">
<li>분류문제(classification) 이항회귀모형과 연속형 예측 선형회귀모형은 최종적으로 선정되는 예측모형과 벤치마크 성능을 비교하는 지표로 필히 실행하여 선정한다.</li>
<li>기계학습 모형을 최종 모형으로 선정할 때 해석용이성은 떨어지지만, 가장 성능이 좋은 모형으로 선정한다. 예를 들어, 부스팅 나무모형(Boosting Tree Models), 지지도 벡터 머신(Support Vector Machine, SVM)으로 시작하는데 이유는 가장 정확한 최적의 결과를 제공하기 때문이다.</li>
<li>최적의 모형이 어떻게 보면 가장 좋은 성능의 상한을 제시하게 되고, 이를 기반으로 최적의 성능에 버금가는 해석이 용이한 모형을 탐색한다. 예를 들어, multivariate adaptive regression splines (MARS), partial least squares, generalized additive models, 나이브 베이즈 모형이 대표적이다.</li>
<li>성능은 복잡성이 높은 모형이 기준이 되고, 검토하는 모형은 가장 단순한 모형으로 선정한다.</li>
</ol>
<h1 id="predictive-model">2. 각 단계별 데이터셋 <a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a></h1>
<p>데이터셋을 훈련(train), 타당성검증(validation), 시험(test) 데이터셋을 나누고 데이터의 역할에 맞게 기계학습 모형 선정에 필요한 기능을 갖추는데 활용한다. 훈련 데이터, 타당성검증 데이터, 시험 데이터는 많은 경우 6:2:2 비율로 나누는 것이 일반적이다. 그리고, 모형을 한번 수행하는 것이 아니라 10-fold 교차검증을 5번 반복하는 것이 좋은 성능을 낸다는 연구결과도 있다.</p>
<p><img src="fig/ml-caret-yardstick.png" alt="기계학습 모형선정 및 평가" width="77%" /></p>
<h1 id="german-credit-data">3. 모형 선정 사례 – 독일신용평가 데이터</h1>
<h2 id="german-credit-data-import">3.1. 환경설정 및 데이터 가져오기</h2>
<p>독일신용평가 데이터를 <code>caret</code> 팩키지에 포함된 것을 사용한다. 훈련데이터와 검증데이터를 반반 나눈다. <code>createDataPartition</code> 함수를 사용해서 쉽게 사용한다. <code>sample</code> 함수를 사용해도 좋다. 데이터 전처리가 깔끔히 되어 있으니 생략한다. 필요하면 더 작업을 해도 좋다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 0. 환경설정 ------</span>
<span class="kw">library</span>(caret)
<span class="kw">library</span>(tidyverse)
<span class="kw">library</span>(yardstick)</code></pre></div>
<pre class="output"><code>Error in library(yardstick): there is no package called &#39;yardstick&#39;
</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 1. 데이터 ------</span>
## 1.1. 데이터 가져오기
<span class="kw">data</span>(GermanCredit)</code></pre></div>
<h2 id="german-credit-data-split">3.2. 데이터 분할</h2>
<p><code>createDataPartition()</code> 함수를 사용해서 우선 훈련 데이터를 먼저 발래내고, 다음으로 타당성검증과 시험 데이터를 순차적으로 발라낸다. 이때, 일반적인 데이터 분할 사례 6:2:2를 반영한다. 즉, 훈련데이터 60%, 타당성검증 데이터 20%, 시험데이터 20%를 반영한다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## 1.2. 데이터 분할: 훈련, 타당성검증, 시험
### 훈련 vs 검증/시험
in_train &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(GermanCredit$Class, <span class="dt">p =</span> <span class="kw">c</span>(<span class="fl">0.6</span>, <span class="fl">0.4</span>), <span class="dt">list =</span> <span class="ot">FALSE</span>)

training &lt;-<span class="st"> </span>GermanCredit[in_train, ]
validation_test &lt;-<span class="st"> </span>GermanCredit[-in_train, ]

### 타당성검증 vs 시험
in_test &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(validation_test$Class, <span class="dt">p =</span> <span class="kw">c</span>(<span class="fl">0.5</span>, <span class="fl">0.5</span>), <span class="dt">list =</span> <span class="ot">FALSE</span>)

validation &lt;-<span class="st"> </span>validation_test[-in_test, ]
testing &lt;-<span class="st"> </span>validation_test[in_test, ]</code></pre></div>
<h2 id="german-credit-model-formula">3.3. 모형공식</h2>
<p>R에 공식 비공식적으로 10,000개가 넘는 팩키지가 존재하고 각 팩키지마다 모형을 명세하는 방식이 다르다. 크게 <code>~</code> 공식을 사용하는 방식과 데이터프레임 <code>=</code> 을 사용하는 방식이 있는데 팩키지마다 공식을 명세하는 방식을 준용하면 된다. 중요한 것은 <code>~</code>, <code>=</code> 좌측은 종속변수, 우측은 독립변수가 위치해 넣으면 된다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 2. 예측모형 개발 ------</span>
## 2.1. 예측모형 공식 

credit_var &lt;-<span class="st"> </span><span class="kw">setdiff</span>(<span class="kw">colnames</span>(training), <span class="kw">list</span>(<span class="st">&#39;Class&#39;</span>))
credit_formula &lt;-<span class="st"> </span><span class="kw">as.formula</span>(<span class="kw">paste</span>(<span class="st">&#39;Class&#39;</span>, <span class="kw">paste</span>(credit_var, <span class="dt">collapse=</span><span class="st">&#39; + &#39;</span>), <span class="dt">sep=</span><span class="st">&#39; ~ &#39;</span>))</code></pre></div>
<h2 id="german-credit-model-architecture">3.4. 모형 아키텍처</h2>
<p>일반화선형모형(GLM)을 벤치마킹 기본 모형으로 잡고, 독일신용평가 데이터는 분류문제로 CART 모형도 예측모형에 포함하고 <code>Random Forest</code>, GBM, xgBoost를 선택해야하는 모형 아키텍처에 포함시킨다. 모형을 차례로 적합시켜 <strong>성능</strong>은 가장 뛰어나면서,</p>
<ol style="list-style-type: decimal">
<li>가장 단순한 모형</li>
<li>가장 이해하기 쉬운 모형</li>
<li>가장 실운영환경에 배포하기 좋은 모형</li>
</ol>
<p>이런 모형을 선정한다. 이를 위한 판단기준으로 타당성검증(validation) 데이터를 활용한다. 타당성검증(validation) 데이터는 물론 훈련과정에 포함된 적은 없다.</p>
<p><code>trainControl()</code> 함수에 <code>method = 'cv'</code>로 설정하게 되면 10-fold 가 지정된다. 이를 반복해서 5회하는 것이 성능이 좋은 것으로 알려져 있다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## 2.2. 예측모형 아키텍처 
ml_control &lt;-<span class="st"> </span><span class="kw">trainControl</span>(<span class="dt">method =</span> <span class="st">&quot;repeatedcv&quot;</span>, 
                           <span class="dt">number =</span> <span class="dv">10</span>, 
                           <span class="dt">repeats =</span> <span class="dv">5</span>,
                           <span class="dt">sampling =</span> <span class="st">&quot;up&quot;</span>,
                           <span class="dt">verboseIter=</span><span class="ot">FALSE</span>)

### 2.2.1. 벤치마크 모형 - 이항회귀모형 적합
glm_m &lt;-<span class="st"> </span><span class="kw">train</span>(credit_formula, <span class="dt">data =</span> training,
                        <span class="dt">method =</span> <span class="st">&quot;glm&quot;</span>, <span class="dt">family=</span><span class="kw">binomial</span>(<span class="dt">link=</span><span class="st">&#39;logit&#39;</span>),
                        <span class="dt">trControl =</span> ml_control)

### 2.2.2. 의사결정나무모형(cart)
cart_m &lt;-<span class="st"> </span><span class="kw">train</span>(credit_formula, <span class="dt">data =</span> training,
                <span class="dt">method =</span> <span class="st">&quot;rpart&quot;</span>,
                <span class="dt">trControl =</span> <span class="kw">trainControl</span>(<span class="dt">method =</span> <span class="st">&quot;none&quot;</span>,
                                         <span class="dt">sampling =</span> <span class="st">&quot;up&quot;</span>))

### 2.2.3. 확률숲(Random Forest)
rf_m &lt;-<span class="st"> </span><span class="kw">train</span>(credit_formula, <span class="dt">data =</span> training,
                 <span class="dt">method =</span> <span class="st">&quot;rf&quot;</span>,
                 <span class="dt">trControl =</span> ml_control)

### 2.2.4. gbm
gbm_m &lt;-<span class="st"> </span><span class="kw">train</span>(credit_formula, <span class="dt">data =</span> training,
                     <span class="dt">method =</span> <span class="st">&quot;gbm&quot;</span>,
                     <span class="dt">trControl =</span> ml_control,
                     <span class="dt">verbose =</span> <span class="ot">FALSE</span>)

### 2.2.5. xgBoost
xgboost_m &lt;-<span class="st"> </span><span class="kw">train</span>(credit_formula, <span class="dt">data =</span> training,
                     <span class="dt">method =</span> <span class="st">&quot;xgbLinear&quot;</span>,
                     <span class="dt">trControl =</span> ml_control)</code></pre></div>
<h2 id="german-credit-model-choose">3.5. 모형 아키텍처 선정</h2>
<p>이항회귀모형, 의사결정나무, 확률숲(randomForest), GBM, xgBoost 모형의 성능을 정확도(accuracy)를 기준으로 각각 비교한다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## 2.3. 모형 아키텍처 선정 
model_arch &lt;-<span class="st"> </span>validation %&gt;%
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">GLM =</span> <span class="kw">predict</span>(glm_m, validation),
           <span class="dt">CART =</span> <span class="kw">predict</span>(cart_m, validation),
           <span class="dt">RF =</span> <span class="kw">predict</span>(rf_m, validation),
           <span class="dt">XGB =</span> <span class="kw">predict</span>(xgboost_m, validation),
           <span class="dt">GBM =</span> <span class="kw">predict</span>(gbm_m, validation))

<span class="kw">metrics</span>(model_arch, <span class="dt">truth =</span> Class, <span class="dt">estimate =</span> GLM)</code></pre></div>
<pre class="output"><code>Error in metrics(model_arch, truth = Class, estimate = GLM): 함수 &quot;metrics&quot;를 찾을 수 없습니다
</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">metrics</span>(model_arch, <span class="dt">truth =</span> Class, <span class="dt">estimate =</span> CART)</code></pre></div>
<pre class="output"><code>Error in metrics(model_arch, truth = Class, estimate = CART): 함수 &quot;metrics&quot;를 찾을 수 없습니다
</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">metrics</span>(model_arch, <span class="dt">truth =</span> Class, <span class="dt">estimate =</span> RF)</code></pre></div>
<pre class="output"><code>Error in metrics(model_arch, truth = Class, estimate = RF): 함수 &quot;metrics&quot;를 찾을 수 없습니다
</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">metrics</span>(model_arch, <span class="dt">truth =</span> Class, <span class="dt">estimate =</span> GBM)</code></pre></div>
<pre class="output"><code>Error in metrics(model_arch, truth = Class, estimate = GBM): 함수 &quot;metrics&quot;를 찾을 수 없습니다
</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">metrics</span>(model_arch, <span class="dt">truth =</span> Class, <span class="dt">estimate =</span> XGB)</code></pre></div>
<pre class="output"><code>Error in metrics(model_arch, truth = Class, estimate = XGB): 함수 &quot;metrics&quot;를 찾을 수 없습니다
</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># predict(glm_m, validation, type=&quot;prob&quot;)</span></code></pre></div>
<p>사실 모형 아키텍처에 포함된 모든 모형이 동일한 값을 주지는 않는다. 차이가 크다고 하더라도 확률적인 요인에 의한 차이로 밝혀질 수도 있다. 이런 경우 쌍체 <span class="math inline">\(t\)</span>-검증 (paired t-test)을 사용하여 모형간 유의성을 검증한다. 만약 차이점이 없다면 가장 단순한 모형을 선택한다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">diff_test &lt;-<span class="st"> </span><span class="kw">resamples</span>(<span class="kw">list</span>(<span class="dt">GLM =</span> glm_m, 
                            <span class="dt">XGB =</span> xgboost_m))
<span class="kw">summary</span>(diff_test)</code></pre></div>
<pre class="output"><code>
Call:
summary.resamples(object = diff_test)

Models: GLM, XGB 
Number of resamples: 50 

Accuracy 
         Min.   1st Qu.    Median      Mean   3rd Qu. Max. NA&#39;s
GLM 0.5666667 0.6500000 0.7000000 0.6880000 0.7333333  0.8    0
XGB 0.6000000 0.6833333 0.7166667 0.7253333 0.7500000  0.9    0

Kappa 
          Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA&#39;s
GLM 0.08088235 0.2315447 0.3440519 0.3248065 0.4354193 0.5522388    0
XGB 0.01639344 0.2163625 0.3286830 0.3250742 0.3750000 0.7368421    0
</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">diff</span>(diff_test) %&gt;%<span class="st"> </span>summary</code></pre></div>
<pre class="output"><code>
Call:
summary.diff.resamples(object = .)

p-value adjustment: bonferroni 
Upper diagonal: estimates of the difference
Lower diagonal: p-value for H0: difference = 0

Accuracy 
    GLM      XGB     
GLM          -0.03733
XGB 0.004676         

Kappa 
    GLM    XGB       
GLM        -0.0002678
XGB 0.9926           
</code></pre>
<h2 id="german-credit-model-choose">3.6. 최종 모형 성능</h2>
<p>최종적으로 모형의 성능을 <code>testing</code> 검증데이터를 통해서 사전에 선정한 측도(정확도, <code>accuracy</code>)를 통해 반영한다. <code>xgboost</code> 모형과 <code>GLM</code> 모형의 차이만큼을 모형 성능으로 보고 이를 예측모형으로 적용시킨다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 3. 모형성능 ------</span>
testing_perf &lt;-<span class="st"> </span>testing %&gt;%
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">GLM =</span> <span class="kw">predict</span>(glm_m, testing),
           <span class="dt">XGB =</span> <span class="kw">predict</span>(xgboost_m, testing))

<span class="kw">metrics</span>(testing_perf, <span class="dt">truth =</span> Class, <span class="dt">estimate =</span> GLM)</code></pre></div>
<pre class="output"><code>Error in metrics(testing_perf, truth = Class, estimate = GLM): 함수 &quot;metrics&quot;를 찾을 수 없습니다
</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">metrics</span>(testing_perf, <span class="dt">truth =</span> Class, <span class="dt">estimate =</span> XGB)</code></pre></div>
<pre class="output"><code>Error in metrics(testing_perf, truth = Class, estimate = XGB): 함수 &quot;metrics&quot;를 찾을 수 없습니다
</code></pre>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p><a href="https://arxiv.org/abs/1708.05070v1">Randal S. Olson, William La Cava, Zairah Mustahsan, Akshay Varik, Jason H. Moore(2018), “Data-driven Advice for Applying Machine Learning to Bioinformatics Problems”</a><a href="#fnref1">↩</a></p></li>
<li id="fn2"><p><a href="http://link.springer.com/book/10.1007/978-1-4614-6849-3">Kuhn, Max, and Kjell Johnson. Applied predictive modeling. New York: Springer, 2013.</a><a href="#fnref2">↩</a></p></li>
<li id="fn3"><p><a href="http://link.springer.com/book/10.1007/978-1-4614-6849-3">Kuhn, Max, and Kjell Johnson. Applied predictive modeling. New York: Springer, 2013.</a><a href="#fnref3">↩</a></p></li>
</ol>
</div>
        </div>
      </div>
      </article>
      <div class="footer">
        <a class="label swc-blue-bg" href="http://software-carpentry.org">Software Carpentry</a>
        <a class="label swc-blue-bg" href="https://github.com/swcarpentry/lesson-template">Source</a>
        <a class="label swc-blue-bg" href="mailto:admin@software-carpentry.org">Contact</a>
        <a class="label swc-blue-bg" href="LICENSE.html">License</a>
      </div>
    </div>
    <!-- Javascript placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
    <script src="css/bootstrap/bootstrap-js/bootstrap.js"></script>
    <script src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>
  </body>
</html>
