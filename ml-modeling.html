<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="generator" content="pandoc">
    <title>Software Carpentry: xwMOOC 기계학습</title>
    <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="stylesheet" type="text/css" href="css/bootstrap/bootstrap.css" />
    <link rel="stylesheet" type="text/css" href="css/bootstrap/bootstrap-theme.css" />
    <link rel="stylesheet" type="text/css" href="css/swc.css" />
    <link rel="alternate" type="application/rss+xml" title="Software Carpentry Blog" href="http://software-carpentry.org/feed.xml"/>
    <meta charset="UTF-8" />
    <!-- HTML5 shim, for IE6-8 support of HTML5 elements -->
    <!--[if lt IE 9]>
      <script src="https://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
    
      ga('create', 'UA-59802572-17', 'auto');
      ga('send', 'pageview');
    
    </script>
  </head>
  <body class="lesson">
    <div class="container card">
      <div class="banner">
        <a href="http://software-carpentry.org" title="Software Carpentry">
          <img alt="Software Carpentry banner" src="img/software-carpentry-banner.png" />
        </a>
      </div>
      <article>
      <div class="row">
        <div class="col-md-10 col-md-offset-1">
                    <a href="index.html"><h1 class="title">xwMOOC 기계학습</h1></a>
          <h2 class="subtitle">데이터 적합 모형 개발</h2>
          <section class="objectives panel panel-warning">
<div class="panel-heading">
<h2 id="학습목표"><span class="glyphicon glyphicon-certificate"></span>학습목표</h2>
</div>
<div class="panel-body">
<ul>
<li>전통적 통계모형과 비교하여 예측모형에 대해 이해한다.</li>
<li>예측모형을 R에서 직접 실행한다.</li>
<li><code>caret</code> 팩키지의 10년에 걸친 여정을 살펴본다.</li>
</ul>
</div>
</section>
<h2 id="전통적-통계모형과-예측모형-비교">1. 전통적 통계모형과 예측모형 비교</h2>
<p><a href="https://en.wikipedia.org/wiki/Predictive_modelling">예측모형(Predictive Model)</a>은 정확도가 높은 모형을 개발하는 과정이다. 따라서, 전통적 통계학에서 강조하는 추론, 타당성, 유의성, 가정과 같은 개념적인 것보다는 “실질적으로 정확하게 예측을 할 수 있는가?” 라는 문제늘 더 중요하게 다루고 있다.</p>
<aside class="callout panel panel-info">
<div class="panel-heading">
<h3 id="예측모형-정의predictive-modeling"><span class="glyphicon glyphicon-pushpin"></span>예측모형 정의(Predictive Modeling)</h3>
</div>
<div class="panel-body">
<p>“Predictive Modeling is the process of creating a model whose primary goal is to achieve high levels of accuracy.”<br />
– Max Kuhn from Pfizer R&amp;D</p>
</div>
</aside>
<p><strong>예측모형에서 중요하게 고려되는 사항</strong></p>
<ul>
<li>예측모형 성능</li>
<li>예측의 단순성</li>
<li>복잡성과 컴퓨팅 비용을 줄이도록 변수(특성, Feature) 축소</li>
<li>예측수식 평활(smoothness)</li>
<li>예측모형의 강건성</li>
</ul>
<p><img src="fig/ml-parameter-tuning.png" alt="예측모형 개발과정" width="70%" ></p>
<h2 id="caret-팩키지">2. <code>caret</code> 팩키지</h2>
<p><code>caret</code> 팩키지와 같은 예측모형 전용 팩키지가 필요한 이유는 너무나 많은 예측모형이 존재하고, 더 큰 문제는 사용법과 해석이 모두 다르다는데 있다. 너무 많은 사람이들이 오랜기간에 걸쳐 개발하다보니 어쩌면 당연한 문제라고 볼 수도 있다.</p>
<h3 id="r-팩키지-구문">2.1. R 팩키지 구문</h3>
<p>기계학습에서 가장 많이 작업하는 것 중에 하나가 분류문제에 대한 예측 알고리즘을 제시하는 것이다. 데이터도 다양하지만, 분류문제에 대한 다양한 이론이 존재하고, R로 구현된 팩키지도 정말 다양한다. 예를 들어, <code>lda</code>는 판별분석(Linear Discrimant Analsyis)을 돌릴 때 사용되는 것으로 <code>MASS</code> 팩키지에 포함되어 있고, 훈련데이터 혹은 검증데이터에 예측값을 구할 경우 <code>predict</code> 함수에 <code>lda</code> 반환값을 넣어주면 되고 추가설정은 필요없다. <code>glm</code>은 일반화 선형모형을 적합할 때 특히 링크함수로 <code>logit</code>을 넣어 설정하고 <code>stats</code> 팩키지에 포함되어 있고, 구문은 <code>lda</code>와 확연한 차이를 볼 수 있다. <code>gbm</code>, <code>mda</code>, <code>rpart</code>, <code>Weka</code>, <code>LogitBoost</code>등 다양한 예측 알고리즘이 존재한다. 다음은 <strong>Max Kuhn</strong> 박사가 <code>caret</code>을 개발한 주요한 사유로 정리한 표다. 이를 일관된 인터페이스로 제공하고 나아가 각 모형의 성능을 객관적으로 비교할 수 있는 성능평가 지표 도출 및 확정을 위해서 꼭 필요한 것으로 판단된다. (본인이 필요해서 개발하지 않았을까 생각되고, 누구나 이런 코드는 갖고 있는데 체계적으로 정리해서 공개한 후, 10년에 걸쳐 시간을 투여한 Kuhn 박사님께 감사드립니다.)</p>
<table>
<thead>
<tr class="header">
<th align="center">예측함수명</th>
<th align="center">팩키지명</th>
<th align="left"><code>predict</code> 함수 예측구문</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">lda</td>
<td align="center">MASS</td>
<td align="left">predict(obj) (추가 인자설정 불필요)</td>
</tr>
<tr class="even">
<td align="center">glm</td>
<td align="center">stats</td>
<td align="left">predict(obj, type = “response”)</td>
</tr>
<tr class="odd">
<td align="center">gbm</td>
<td align="center">gbm</td>
<td align="left">predict(obj, type = “response”, n.trees)</td>
</tr>
<tr class="even">
<td align="center">mda</td>
<td align="center">mda</td>
<td align="left">predict(obj, type = “posterior”)</td>
</tr>
<tr class="odd">
<td align="center">rpart</td>
<td align="center">rpart</td>
<td align="left">predict(obj, type = “prob”)</td>
</tr>
<tr class="even">
<td align="center">Weka</td>
<td align="center">RWeka</td>
<td align="left">predict(obj, type = “probability”)</td>
</tr>
<tr class="odd">
<td align="center">LogitBoost</td>
<td align="center">caTools</td>
<td align="left">predict(obj, type = “raw”, nIter)</td>
</tr>
</tbody>
</table>
<h3 id="기계학습-알고리듬-pedro">2.2. 기계학습 알고리듬 <a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a></h3>
<p>컴퓨터 기계가 학습을 하는 것은 흥미로운 주제로 5가지 패러다임으로 페드로 박사님께서 범주화하셨습니다.</p>
<ul>
<li>기호주의자(symbolist) : 역추론(inverse deduction) → 전문가 시스템(Expert System)</li>
<li>연결주의자(connectionist) : 역전파(backpropagation) → 신경망/딥러닝</li>
<li>진화론자(evolutionist) : 유전자 프로그래밍(genetic programming) → 유전자 알고리듬(Genetic Programming)</li>
<li>베이즈(Bayesian) : 베이즈 추론(Bayesian inference) → 깁스 표집, MCMC</li>
<li>유사주의자(analogizer) : 통계적 학습(Statistical Learning) → 지지도 벡터 머신(Support vector machine)</li>
</ul>
<p><code>caret</code>에서 지원하는 예측모형 목록 중 일부는 다음과 같고, 전체 목록은 <a href="http://topepo.github.io/caret/modelList.html">예측모형 caret 목록</a>을 참조한다. 2014년 2월 기준 예측모형과 예측함수 147개, 2016년 1월 기준 216개 폭증.</p>
<table>
<thead>
<tr class="header">
<th align="left">모형</th>
<th align="left">예측함수명</th>
<th align="left">팩키지</th>
<th align="left">세부조정 모수</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">재귀적 분할</td>
<td align="left">rpart</td>
<td align="left">rpart</td>
<td align="left">maxdepth</td>
</tr>
<tr class="even">
<td align="left">Boosted trees</td>
<td align="left">gbm</td>
<td align="left">gbm</td>
<td align="left">interaction.depth, n.trees, shrinkage</td>
</tr>
<tr class="odd">
<td align="left">Random forests</td>
<td align="left">rf</td>
<td align="left">randomForest</td>
<td align="left">mtry</td>
</tr>
<tr class="even">
<td align="left">신경망</td>
<td align="left">nnet</td>
<td align="left">nnet</td>
<td align="left">decay, size</td>
</tr>
<tr class="odd">
<td align="left">Support Vector Machine (RBF 커널)</td>
<td align="left">svmRadial</td>
<td align="left">kernlab</td>
<td align="left">sigma, C</td>
</tr>
<tr class="even">
<td align="left">Support Vector Machine (다항식 커널)</td>
<td align="left">svmPoly</td>
<td align="left">kernlab</td>
<td align="left">scale, degree, C</td>
</tr>
<tr class="odd">
<td align="left">선형회귀</td>
<td align="left">lm</td>
<td align="left">stats</td>
<td align="left">없음</td>
</tr>
<tr class="even">
<td align="left">…</td>
<td align="left">…</td>
<td align="left">…</td>
<td align="left">…</td>
</tr>
</tbody>
</table>
<h2 id="고객-이탈-예측-사례">3. 고객 이탈 예측 사례</h2>
<p>고객 이탈(churn)은 마케팅을 통한 고객획득과 마찬가지로 상당히 중요한 의미를 갖는다. 고객이탈을 고객유지(retention)의 반대쪽 면으로 볼 수 있고, 고객평생가치적인 측면에서도 상당히 중요한 사업적 의미를 갖는다. <a href="http://www.sgi.com/tech/mlc/">SGI, Silicon Graphics International</a>에도 상당히 좋은 데이터를 많이 제공하고 있다. <a href="http://www.sgi.com/tech/mlc/db/">churn.all, churn.data, churn.names, churn.test</a>데이터를 활용하여 직접 예측모형을 개발한다.</p>
<h3 id="고객이탈-데이터-준비">3.1. 고객이탈 데이터 준비</h3>
<p><code>C50</code> 팩키지에 <code>churn</code> 데이터로 준비되어 있어, 굳이 웹사이트에서 다운로드 받아 이를 가공하는 과정을 생략할 수 있다. <code>data(churn)</code> 명령어를 수행하면 <code>ls()</code> 명령어를 통해서 <code>churnTest</code>, <code>churnTrain</code> 데이터프레임이 생성된 것을 확인하게 된다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">suppressMessages</span>(<span class="kw">library</span>(pROC))
<span class="kw">suppressMessages</span>(<span class="kw">library</span>(C50))
<span class="kw">data</span>(churn)
<span class="kw">ls</span>()</code></pre></div>
<pre class="output"><code>[1] &quot;churnTest&quot;  &quot;churnTrain&quot; &quot;hook_in&quot;    &quot;hook_out&quot;  
</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">suppressMessages</span>(<span class="kw">library</span>(doMC))
<span class="kw">registerDoMC</span>(<span class="dt">cores=</span><span class="dv">7</span>)
<span class="kw">suppressMessages</span>(<span class="kw">library</span>(caret))</code></pre></div>
<h3 id="기계학습-훈련-검증-데이터-쪼개기">3.2. 기계학습 훈련-검증 데이터 쪼개기</h3>
<p><code>churnTest</code>, <code>churnTrain</code> 데이터프레임을 <code>allData</code>로 결합한다. 그리고 나서, 훈련데이터와 검증데이터를 75:25 비율로 나눈다. <code>caret</code> 팩키지에 데이터를 쪼개는 다양한 방법을 제공하고 있어, <code>createFolds</code>, <code>createMultiFolds</code>, <code>createResamples</code> 함수를 필요에 따라 사용한다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 데이터 나누기</span>
allData &lt;-<span class="st"> </span><span class="kw">rbind</span>(churnTrain, churnTest)

inTrainingSet &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(allData$churn, <span class="dt">p =</span> .<span class="dv">75</span>, <span class="dt">list =</span> <span class="ot">FALSE</span>)
churnTrain &lt;-<span class="st"> </span>allData[ inTrainingSet,]
churnTest &lt;-<span class="st"> </span>allData[-inTrainingSet,]

<span class="co"># 설명변수만 추출</span>
predictors &lt;-<span class="st"> </span><span class="kw">names</span>(churnTrain)[<span class="kw">names</span>(churnTrain) !=<span class="st"> &quot;churn&quot;</span>]</code></pre></div>
<h3 id="부스팅-나무-모수-세부조정">3.3. 부스팅 나무 모수 세부조정</h3>
<p><code>부스팅(Boosted Tree)</code> 모형을 <code>caret</code>에 적용하기 전에 먼저 이탈여부(“yes”, “no”)를 재코딩해야된다. 왜냐면, <code>gbm</code>에서 종속변수를 요인 자료형을 받지 않기 때문이다. <code>trainControl</code>에 <code>twoClassSummary</code>를 지정하면, 민감도(Sensitivity), 특이성(specificity), AUC 면적을 함께 확인하고, 제어에 활용할 수 있다.</p>
<p>최고성능을 내는 모수를 찾기 위해서 <code>expand.grid</code>에 <code>gbm</code>관련 설정을 한다. <code>shrinkage</code>는 0.01과 0.1로 설정하고, <code>n.trees</code> 나무갯수는 100에서 1000까지 100만큼 증가시켜 10회 반복한다. <code>interaction.depth</code>는 나무노드를 쪼개는 회수를 지정한다. 따라서, 나무 깊이가 1,3,5,7로 깊어지고 나무가 풍성해진다.</p>
<p><code>metric = &quot;ROC&quot;</code> 모수 설정을 통해 최적 모수가 <code>ROC</code> 면적이 가장 큰 것이 교차타당도 결과 자동 선정된다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## 종속변수(이탈여부, &quot;yes&quot;, &quot;no&quot;) 재코딩
forGBM &lt;-<span class="st"> </span>churnTrain
forGBM$churn &lt;-<span class="st"> </span><span class="kw">ifelse</span>(forGBM$churn ==<span class="st"> &quot;yes&quot;</span>, <span class="dv">1</span>, <span class="dv">0</span>)

<span class="kw">suppressMessages</span>(<span class="kw">library</span>(gbm))
ctrl &lt;-<span class="st"> </span><span class="kw">trainControl</span>(<span class="dt">method =</span> <span class="st">&quot;repeatedcv&quot;</span>, <span class="dt">repeats =</span> <span class="dv">5</span>,
                     <span class="dt">classProbs =</span> <span class="ot">TRUE</span>,
                     <span class="dt">summaryFunction =</span> twoClassSummary)

grid &lt;-<span class="st"> </span><span class="kw">expand.grid</span>(<span class="dt">interaction.depth =</span> <span class="kw">seq</span>(<span class="dv">1</span>, <span class="dv">7</span>, <span class="dt">by =</span> <span class="dv">2</span>),
                    <span class="dt">n.trees =</span> <span class="kw">seq</span>(<span class="dv">100</span>, <span class="dv">1000</span>, <span class="dt">by =</span> <span class="dv">100</span>),
                    <span class="dt">shrinkage =</span> <span class="kw">c</span>(<span class="fl">0.01</span>, <span class="fl">0.1</span>), 
                    <span class="dt">n.minobsinnode =</span> <span class="dv">10</span>)

gbmTune &lt;-<span class="st"> </span><span class="kw">train</span>(churn ~<span class="st"> </span>., <span class="dt">data =</span> churnTrain,
                 <span class="dt">method =</span> <span class="st">&quot;gbm&quot;</span>,
                 <span class="dt">metric =</span> <span class="st">&quot;ROC&quot;</span>,
                 <span class="dt">tuneGrid =</span> grid,
                 <span class="dt">verbose =</span> <span class="ot">FALSE</span>,
                 <span class="dt">trControl =</span> ctrl)</code></pre></div>
<pre class="output"><code>Loading required package: plyr
</code></pre>
<h3 id="최종-모형-성능평가-및-검증데이터-예측">3.4. 최종 모형 성능평가 및 검증데이터 예측</h3>
<p>나무깊이, <code>shrinkage</code>, 노드 최소 훈련표본 갯수를 기반으로 ROC 면적이 교차타당도 결과로 산출되고 가장 좋은 것을 선정한다.</p>
<p><code>gbmTune</code> 결과를 바탕으로 <code>confusionMatrix</code>에 넣어 모형 성능을 가늠한다.</p>
<p>검증데이터(향후, 신규 예측이 필요한 데이터)에 고객이탈 확률과 고객보유확률을 <code>predict</code> 함수로 예측한다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 최적모수 선정 시각화</span>
<span class="kw">ggplot</span>(gbmTune) +<span class="st"> </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;top&quot;</span>)</code></pre></div>
<p><img src="fig/churn-gbm-assessment-1.png" title="plot of chunk churn-gbm-assessment" alt="plot of chunk churn-gbm-assessment" style="display: block; margin: auto;" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 최적 모형 성능 평가</span>
gbmPred &lt;-<span class="st"> </span><span class="kw">predict</span>(gbmTune, churnTest)
<span class="kw">confusionMatrix</span>(gbmPred, churnTest$churn)</code></pre></div>
<pre class="output"><code>Confusion Matrix and Statistics

          Reference
Prediction  yes   no
       yes  124    6
       no    52 1067
                                          
               Accuracy : 0.9536          
                 95% CI : (0.9404, 0.9646)
    No Information Rate : 0.8591          
    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
                                          
                  Kappa : 0.7847          
 Mcnemar&#39;s Test P-Value : 3.446e-09       
                                          
            Sensitivity : 0.70455         
            Specificity : 0.99441         
         Pos Pred Value : 0.95385         
         Neg Pred Value : 0.95353         
             Prevalence : 0.14091         
         Detection Rate : 0.09928         
   Detection Prevalence : 0.10408         
      Balanced Accuracy : 0.84948         
                                          
       &#39;Positive&#39; Class : yes             
                                          
</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 검증데이터 고객이탈 확률과 고객보유확률 예측</span>
gbmProbs &lt;-<span class="st"> </span><span class="kw">predict</span>(gbmTune, churnTest, <span class="dt">type =</span> <span class="st">&quot;prob&quot;</span>)
<span class="kw">head</span>(gbmProbs)</code></pre></div>
<pre class="output"><code>         yes        no
1 0.03023747 0.9697625
2 0.05412460 0.9458754
3 0.67664526 0.3233547
4 0.68258206 0.3174179
5 0.97999220 0.0200078
6 0.03178743 0.9682126
</code></pre>
<h3 id="proc-팩키지-roc-곡선">3.5. <code>pROC</code> 팩키지 ROC 곡선</h3>
<p><code>pROC</code> 팩키지 ROC 곡선을 통해 민감도와 특이성에 대한 자세한 정보를 확인할 수 있다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rocCurve &lt;-<span class="st"> </span><span class="kw">roc</span>(<span class="dt">response =</span> churnTest$churn,
                <span class="dt">predictor =</span> gbmProbs[, <span class="st">&quot;yes&quot;</span>],
                <span class="dt">levels =</span> <span class="kw">rev</span>(<span class="kw">levels</span>(churnTest$churn)))
rocCurve</code></pre></div>
<pre class="output"><code>
Call:
roc.default(response = churnTest$churn, predictor = gbmProbs[,     &quot;yes&quot;], levels = rev(levels(churnTest$churn)))

Data: gbmProbs[, &quot;yes&quot;] in 1073 controls (churnTest$churn no) &lt; 176 cases (churnTest$churn yes).
Area under the curve: 0.9127
</code></pre>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p><a href="http://www.amazon.com/Master-Algorithm-Ultimate-Learning-Machine/dp/0465065708">Domingos, Pedro. The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World. Basic Books, 2015.</a><a href="#fnref1">↩</a></p></li>
</ol>
</div>
        </div>
      </div>
      </article>
      <div class="footer">
        <a class="label swc-blue-bg" href="http://software-carpentry.org">Software Carpentry</a>
        <a class="label swc-blue-bg" href="https://github.com/swcarpentry/lesson-template">Source</a>
        <a class="label swc-blue-bg" href="mailto:admin@software-carpentry.org">Contact</a>
        <a class="label swc-blue-bg" href="LICENSE.html">License</a>
      </div>
    </div>
    <!-- Javascript placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
    <script src="css/bootstrap/bootstrap-js/bootstrap.js"></script>
    <script src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>
  </body>
</html>
