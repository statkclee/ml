---
layout: page
title: xwMOOC 기계학습
subtitle: "보험금 청구 사기 예측(fraud detection)"
author:
    name: xwMOOC
    url: https://www.facebook.com/groups/tidyverse/
    affiliation: Tidyverse Korea
date: "`r Sys.Date()`"
output:
  html_document: 
    toc: yes
    toc_float: true
    highlight: tango
    code_folding: show
    number_section: true
    self_contained: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE,
                      comment="", digits = 3, tidy = FALSE, prompt = FALSE, fig.align = 'center')

```



# 보험금 청구 {#insurance-claim}

스마트폰의 보급과 기술의 발달로 인해 보험회사들의 보험금청구 간소화 노력이 빛을 발하고 있다.
더불어 보험금 사기 청구도 늘어나고 있어 빠른 시간내에 사기 보험금 청구를 걸러내고
정상적인 보험금 지급이 빨리 이루어질 수 있도록 조치가 필요하다.

# 보험금 청구 데이터 [^databrick-insurance] {#insurance-claim-dataset}

[^databrick-insurance]: [Databricks, "Insurance Claims - Fraud Detection"](https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/4954928053318020/1058911316420443/167703932442645/latest.html)

보험청구사기는 미국에서 한해 $30 billion 달러로 추산된다. 국내에서도 보험사기 규모가 연간 4.5조에 달할 것이라고 한다. [^korea-fraud] 

[^korea-fraud]: [박상빈 기자  2018.04.25. 14:11, "보험사기 규모 연간 4.5조..금감원·국회, 근절방안 모색",  머니투데이](https://www.msn.com/ko-kr/money/topstories/%EB%B3%B4%ED%97%98%EC%82%AC%EA%B8%B0-%EA%B7%9C%EB%AA%A8-%EC%97%B0%EA%B0%84-45%EC%A1%B0%EA%B8%88%EA%B0%90%EC%9B%90%C2%B7%EA%B5%AD%ED%9A%8C-%EA%B7%BC%EC%A0%88%EB%B0%A9%EC%95%88-%EB%AA%A8%EC%83%89/ar-AAwiHp1)

[보험사기 데이터](https://raw.githubusercontent.com/jodb/sparkTestData/master/insurance_claims.csv)를 다운로드 받아 보험사기 예측모형을 구축한다. 먼저 보험사기로 밝혀진 사례가 전체 1000개 중 몇건인지 살펴본다.

```{r insurance-dataset}
library(tidyverse)

ins_dat <- read_csv("data/insurance_claims.csv", na = "?")

ins_dat %>% 
  count(fraud_reported) %>% 
  mutate(pcnt = n /sum(n))
```

# feature 공학 {#insurance-claim-feature}

[Vishal (February 11, 2019), "Insurance Claims Fraud Detection - Part 1"](https://www.analyzeinsights.com/single-post/2018/05/01/Insurance-Claims-Fraud-Detection---Part-1) 블로그를 참조하여 불필요한 변수를 제거하고 바로 예측모형 구축으로 돌입한다.

변수 6개('policy_number', 'insured_zip', 'policy_bind_date', 'incident_date', 'incident_location', '_c39', 'auto_year', 'incident_hour_of_the_day')는 특별한 의미가 없기 때문에 제거하고, 결측값도 `property_damage`,  `police_report_available`, `collision_type` 있어 강건한 random forest 예측모형을 결측값 보완없이 사용하도록 한다. 그러면 갖가지 문제가 발생되어... 문제가 클 수 있으니 우선 `NA` 결측값을 "unknown"으로 채워넣도록 한다.

```{r insurance-predictive-model}
ins_df <- ins_dat %>% 
  select(-c('policy_number', 'insured_zip', 'policy_bind_date', 'incident_date', 'incident_location', '_c39', 'auto_year', 'incident_hour_of_the_day')) %>% 
  mutate(fraud_reported = factor(fraud_reported, levels=c("N", "Y"))) %>% 
  mutate(property_damage = ifelse(is.na(property_damage), "unknown", property_damage),
         police_report_available = ifelse(is.na(police_report_available), "unknown", police_report_available),
         collision_type = ifelse(is.na(collision_type), "unknown", collision_type)) %>% 
    mutate_if(is.character, as.factor)

ins_df %>% 
  gather(variable, value) %>% 
  mutate(na_value = is.na(value)) %>% 
  group_by(variable) %>% 
  summarise(na_pcnt = mean(na_value)) %>% 
  arrange(desc(na_pcnt))

ins_df %>% 
  count(collision_type)


```

# 예측모형 [^probably-cutoff] {#insurance-claim-predictive-model}

[^probably-cutoff]: [Davis Vaughan (2019-03-07), Where does probably fit in?](https://cran.rstudio.com/web/packages/probably/vignettes/where-to-use.html)

Random Forest와 GLM 로지스틱 회귀모형을 적합시켜서 성능을 살펴본다.

```{r insurance-claim-predictive-model}
library(tidymodels)
library(parsnip)
library(rsample)

## 훈련/시험 데이터 분할 -----
basetable_split <- initial_split(ins_df, props = 6/10)

train_df <- training(basetable_split)
test_df  <- testing(basetable_split)

## Random Forest 예측모형 -----
rf_model <- rand_forest(trees = 1000, mode = "classification") %>%
  set_engine("randomForest", seed = 63233) %>% 
  fit(fraud_reported ~ ., data = train_df)

# 예측모형 성능평가
rf_prob  <- predict(rf_model, test_df, type="prob")
rf_class <- ifelse(rf_prob[,2] > 0.247, "Y", "N") %>% as.factor

caret::confusionMatrix(rf_class, test_df$fraud_reported)

## GLM 예측모형 -----
glm_model <- logistic_reg() %>%
  set_engine("glm") %>% 
  fit(fraud_reported ~ ., data = train_df)

# 예측모형 성능평가
glm_prob  <- predict(glm_model, test_df, type="prob")
glm_class <- ifelse(glm_prob[,2] > 0.247, "Y", "N") %>% as.factor

caret::confusionMatrix(glm_class, test_df$fraud_reported)
```

