---
layout: page
title: xwMOOC 기계학습
subtitle: 기계학습 예측모형 핵심 개념
output:
  html_document: 
    keep_md: yes
  pdf_document:
    latex_engine: xelatex
mainfont: NanumGothic
---
 
> ## 학습목표 {.objectives}
>
> * 예측모형 튜딩에 대해 이해한다. 특히 하이퍼-파라미터를 데이터를 활용하여 객관적으로 찾아낸다.
> * 범주 예측에 `randomForest` 대신 `ranger`로 모형을 구축한다.
> * 연속형 예측에 `glm` 대신 `glmnet`으로 모형을 구축한다.


``` {r, include=FALSE}
source("tools/chunk-options.R")
library(dplyr)
library(caret)
library(mlbench)
data(BostonHousing)
data(Sonar)
```

### 1. 기계학습 예측모형 비교

단순 나무모형은 데이터에 적합모형 개발에 시간이 많이 걸리지 않지만, 성능이 떨어진다.
물론, 단순 나무모형은 나무형태로 예측모형을 생성해 나가 모형이해와 설명, 커뮤니케이션에는 장점이 많다.
하지만, 성능이 좋지 않아, *배깅(Bagging, Bootsrap Aggregation)*을 사용한다.
배깅은 부츠트랩 표본을 뽑아 단순 나무모형을 적합시켜 나온 결과를 사용하여 성능을 획기적으로 높인다.

확률숲(`randomForest`) 모형에 대한 장단점은 다음과 같다.

**장점** 

1. 초심자가 사용하기 적합
1. 과대적합 문제에 강건.
1. 매우 정확한 비선형 모형.
1. 가장 인기가 있는 기계학습 모형

**단점** 

1. 선형모형에는 없는 *하이퍼-파라미터(Hyper-parameter)*를 설정.
1. 하이퍼-파라미터는 수작업으로 찾아 설정해야 됨.
1. 하이퍼-파라미터는 데이터별로 설정해줘야 하는데, 모형성능에 영향을 많이 준다.
1. 모형에 기본설정된 값을 사용해도 되지만, 직접 미세조정을 해야될 경우도 많다.


